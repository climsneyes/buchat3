import json
import pickle
import numpy as np
from rag_utils import GeminiEmbeddings
from typing import List, Dict, Any, Tuple
import re
from datetime import datetime

class HybridRestaurantSearch:
    def __init__(self, gemini_api_key):
        self.restaurant_data = {}
        self.vector_db = None
        self.embeddings = GeminiEmbeddings(gemini_api_key)
        self.load_data()
    
    def load_data(self):
        """JSON ë°ì´í„°ì™€ ë²¡í„°DB ë¡œë“œ"""
        print("ë§›ì§‘ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # 1. JSON ë°ì´í„° ë¡œë“œ
        try:
            with open('ë¶€ì‚°ì˜ë§›(2025).json', 'r', encoding='utf-8') as f:
                busan_food = json.load(f)
            
            with open('íƒìŠë­(2025).json', 'r', encoding='utf-8') as f:
                taxi_ranking = json.load(f)
            
            # ë°ì´í„° í†µí•© ë° ì •ê·œí™”
            self.restaurant_data = self.normalize_restaurant_data(busan_food, taxi_ranking)
            print(f"JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.restaurant_data)}ê°œ ë§›ì§‘")
            
        except Exception as e:
            print(f"JSON ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.restaurant_data = {}
        
        # 2. ë²¡í„°DB ë¡œë“œ (ë¶€ì‚°ì˜ë§›.pklì´ ìˆë‹¤ë©´)
        try:
            with open('ë¶€ì‚°ì˜ë§›.pkl', 'rb') as f:
                self.vector_db = pickle.load(f)
            print("ë²¡í„°DB ë¡œë“œ ì™„ë£Œ")
            
        except FileNotFoundError:
            print("ë²¡í„°DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. JSON ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.vector_db = None
        except Exception as e:
            print(f"ë²¡í„°DB ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.vector_db = None
    
    def normalize_restaurant_data(self, busan_food: Dict, taxi_ranking: Dict) -> List[Dict]:
        """ë§›ì§‘ ë°ì´í„° ì •ê·œí™”"""
        normalized_data = []
        
        # ë¶€ì‚°ì˜ë§› ë°ì´í„° ì²˜ë¦¬
        if "ë¶€ì‚°ì˜ ë§› 2025" in busan_food:
            busan_food_data = busan_food["ë¶€ì‚°ì˜ ë§› 2025"]
            
            for district, restaurants in busan_food_data.items():
                if isinstance(restaurants, list):
                    for restaurant in restaurants:
                        if isinstance(restaurant, dict):
                            # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±
                            search_text_parts = []
                            
                            # ì‹ë‹¹ ì´ë¦„
                            name = ""
                            if "ì‹ë‹¹ì´ë¦„" in restaurant:
                                name_obj = restaurant["ì‹ë‹¹ì´ë¦„"]
                                if isinstance(name_obj, dict):
                                    name = name_obj.get("í•œê¸€", name_obj.get("ì˜ì–´", ""))
                                else:
                                    name = str(name_obj)
                            
                            if name:
                                search_text_parts.append(f"ë§›ì§‘ ì´ë¦„: {name}")
                            
                            # ê°œìš”
                            overview = ""
                            if "ê°œìš”" in restaurant:
                                overview_obj = restaurant["ê°œìš”"]
                                if isinstance(overview_obj, dict):
                                    overview = overview_obj.get("í•œê¸€", overview_obj.get("ì˜ì–´", ""))
                                else:
                                    overview = str(overview_obj)
                            
                            if overview:
                                search_text_parts.append(f"ê°œìš”: {overview}")
                            
                            # ë©”ë‰´
                            menu = ""
                            if "ë©”ë‰´" in restaurant:
                                menu_obj = restaurant["ë©”ë‰´"]
                                if isinstance(menu_obj, dict):
                                    menu = menu_obj.get("í•œê¸€", menu_obj.get("ì˜ì–´", ""))
                                else:
                                    menu = str(menu_obj)
                            
                            if menu:
                                search_text_parts.append(f"ë©”ë‰´: {menu}")
                            
                            # ê¸°íƒ€ ì •ë³´ë“¤
                            address = restaurant.get("ì£¼ì†Œ", "")
                            if address:
                                search_text_parts.append(f"ì£¼ì†Œ: {address}")
                            
                            phone = restaurant.get("ì „í™”ë²ˆí˜¸", "")
                            if phone:
                                search_text_parts.append(f"ì „í™”ë²ˆí˜¸: {phone}")
                            
                            hours = restaurant.get("ì˜ì—…ì‹œê°„", "")
                            if hours:
                                search_text_parts.append(f"ì˜ì—…ì‹œê°„: {hours}")
                            
                            closed = restaurant.get("íœ´ë¬´ì¼", "")
                            if closed:
                                search_text_parts.append(f"íœ´ë¬´ì¼: {closed}")
                            
                            # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¡°í•©
                            search_text = " ".join(search_text_parts)
                            
                            normalized_item = {
                                'name': name,
                                'category': '',  # ë¶€ì‚°ì˜ë§›ì—ëŠ” ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŒ
                                'location': district,
                                'address': address,
                                'phone': phone,
                                'rating': 0,  # ë¶€ì‚°ì˜ë§›ì—ëŠ” í‰ì ì´ ì—†ìŒ
                                'description': overview,
                                'menu': menu,
                                'hours': hours,
                                'closed': closed,
                                'source': 'ë¶€ì‚°ì˜ë§›',
                                'search_text': search_text,
                                'original_data': restaurant
                            }
                            normalized_data.append(normalized_item)
        
        # íƒìŠë­ ë°ì´í„° ì²˜ë¦¬
        if "restaurants" in taxi_ranking:
            restaurants = taxi_ranking["restaurants"]
            
            for restaurant in restaurants:
                if isinstance(restaurant, dict):
                    # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±
                    search_text_parts = []
                    
                    name = restaurant.get("name", "")
                    if name:
                        search_text_parts.append(f"ë§›ì§‘ ì´ë¦„: {name}")
                    
                    overview = restaurant.get("overview", "")
                    if overview:
                        search_text_parts.append(f"ê°œìš”: {overview}")
                    
                    district = restaurant.get("district", "")
                    if district:
                        search_text_parts.append(f"ì§€ì—­: {district}")
                    
                    address = restaurant.get("address", "")
                    if address:
                        search_text_parts.append(f"ì£¼ì†Œ: {address}")
                    
                    phone = restaurant.get("phoneNumber", "")
                    if phone:
                        search_text_parts.append(f"ì „í™”ë²ˆí˜¸: {phone}")
                    
                    hours = restaurant.get("businessHours", "")
                    if hours:
                        search_text_parts.append(f"ì˜ì—…ì‹œê°„: {hours}")
                    
                    closed = restaurant.get("closedDays", "")
                    if closed:
                        search_text_parts.append(f"íœ´ë¬´ì¼: {closed}")
                    
                    # ì¶”ì²œ ë©”ë‰´
                    recommended_menu = restaurant.get("recommendedMenu", [])
                    if recommended_menu:
                        menu_texts = []
                        for menu_item in recommended_menu:
                            if isinstance(menu_item, dict):
                                menu_name = menu_item.get("name", "")
                                menu_price = menu_item.get("price", "")
                                if menu_name and menu_price:
                                    menu_texts.append(f"{menu_name} {menu_price}")
                        if menu_texts:
                            search_text_parts.append(f"ì¶”ì²œë©”ë‰´: {', '.join(menu_texts)}")
                    
                    # ì¶”ì²œ ì´ìœ 
                    reason = restaurant.get("recommendationReason", "")
                    if reason:
                        search_text_parts.append(f"ì¶”ì²œì´ìœ : {reason}")
                    
                    # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¡°í•©
                    search_text = " ".join(search_text_parts)
                    
                    normalized_item = {
                        'name': name,
                        'category': '',  # íƒìŠë­ì—ëŠ” ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŒ
                        'location': district,
                        'address': address,
                        'phone': phone,
                        'rating': 0,  # íƒìŠë­ì—ëŠ” í‰ì ì´ ì—†ìŒ
                        'description': overview,
                        'menu': ', '.join([f"{item.get('name', '')} {item.get('price', '')}" for item in recommended_menu if isinstance(item, dict)]),
                        'hours': hours,
                        'closed': closed,
                        'reason': reason,
                        'source': 'íƒìŠë­',
                        'search_text': search_text,
                        'original_data': restaurant
                    }
                    normalized_data.append(normalized_item)
        
        return normalized_data
    
    def search_by_keywords(self, query: str) -> List[Dict]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (JSON ë°ì´í„°)"""
        query_lower = query.lower()
        results = []
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ë¶„ë¦¬ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)
        search_keywords = query_lower.split()
        
        for restaurant in self.restaurant_data:
            score = 0
            search_text = restaurant['search_text'].lower()
            name_lower = restaurant['name'].lower()
            location_lower = restaurant['location'].lower()
            description_lower = restaurant.get('description', '').lower()
            menu_lower = restaurant.get('menu', '').lower()
            
            # ì •í™•í•œ ë§¤ì¹­ (ë†’ì€ ì ìˆ˜)
            if query_lower in name_lower:
                score += 15
            if query_lower in location_lower:
                score += 12
            if query_lower in description_lower:
                score += 8
            if query_lower in menu_lower:
                score += 6
            
            # ë¶€ë¶„ í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in search_keywords:
                if len(keyword) >= 2:  # 2ê¸€ì ì´ìƒ í‚¤ì›Œë“œë§Œ
                    if keyword in name_lower:
                        score += 10
                    if keyword in location_lower:
                        score += 8
                    if keyword in description_lower:
                        score += 5
                    if keyword in menu_lower:
                        score += 4
                    if keyword in search_text:
                        score += 3
            
            # íŠ¹ì • í‚¤ì›Œë“œ ë§¤ì¹­ (ìŒì‹ ì¢…ë¥˜, ì§€ì—­ ë“±)
            food_keywords = {
                'í•œì‹': ['í•œì‹', 'í•œêµ­', 'êµ­ë°¥', 'êµ­ìˆ˜', 'ë¹„ë¹”ë°¥', 'ê¹€ì¹˜', 'ëœì¥'],
                'ì¤‘ì‹': ['ì¤‘ì‹', 'ì¤‘êµ­', 'ì§œì¥ë©´', 'íƒ•ìˆ˜ìœ¡', 'ë§ˆíŒŒë‘ë¶€', 'ê¹í’ê¸°'],
                'ì¼ì‹': ['ì¼ì‹', 'ì¼ë³¸', 'ì´ˆë°¥', 'ë¼ë©˜', 'ìš°ë™', 'ëˆì¹´ì¸ ', 'ì•¼í‚¤í† ë¦¬'],
                'ì–‘ì‹': ['ì–‘ì‹', 'í”¼ì', 'íŒŒìŠ¤íƒ€', 'ìŠ¤í…Œì´í¬', 'ìƒëŸ¬ë“œ', 'íŒŒìŠ¤íƒ€'],
                'í•´ì‚°ë¬¼': ['í•´ì‚°ë¬¼', 'ìƒì„ ', 'íšŒ', 'ì¡°ê°œ', 'ìƒˆìš°', 'ê²Œ', 'ë¬¸ì–´', 'ì˜¤ì§•ì–´'],
                'ê³ ê¸°': ['ê³ ê¸°', 'ì‚¼ê²¹ì‚´', 'ê°ˆë¹„', 'ë¶ˆê³ ê¸°', 'ë‹­ê°ˆë¹„', 'ë¼ì§€ê³ ê¸°', 'ì†Œê³ ê¸°'],
                'ì¹´í˜': ['ì¹´í˜', 'ì»¤í”¼', 'ë² ì´ì»¤ë¦¬', 'ë””ì €íŠ¸', 'ì¼€ì´í¬', 'ë¹µ'],
                'í”¼ì': ['í”¼ì', 'ë„ë¯¸ë…¸', 'í”¼ìí—›'],
                'ì¹˜í‚¨': ['ì¹˜í‚¨', 'ë‹­', 'í›„ë¼ì´ë“œ', 'ì–‘ë…'],
                'ì„œë©´': ['ì„œë©´', 'ë¶€ì „ë™', 'ë¶€ì „'],
                'í•´ìš´ëŒ€': ['í•´ìš´ëŒ€', 'í•´ìš´ëŒ€êµ¬'],
                'ë‚¨í¬ë™': ['ë‚¨í¬ë™', 'ì¤‘êµ¬'],
                'ê´‘ì•ˆë¦¬': ['ê´‘ì•ˆë¦¬', 'ê´‘ì•ˆëŒ€êµ', 'ìˆ˜ì˜êµ¬'],
                'ë™ë˜': ['ë™ë˜', 'ë™ë˜êµ¬'],
                'ë¶€ì‚°ëŒ€': ['ë¶€ì‚°ëŒ€', 'ê¸ˆì •êµ¬', 'ì¥ì „ë™']
            }
            
            for category, keywords in food_keywords.items():
                if any(keyword in query_lower for keyword in keywords):
                    if any(keyword in search_text for keyword in keywords):
                        score += 7
            
            if score > 0:
                restaurant['match_score'] = score
                results.append(restaurant)
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        results.sort(key=lambda x: x['match_score'], reverse=True)
        return results[:10]  # ìƒìœ„ 10ê°œ
    
    def search_by_semantic(self, query: str) -> List[Dict]:
        """ì˜ë¯¸ì  ê²€ìƒ‰ (ë²¡í„°DB)"""
        if not self.vector_db:
            return []
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.embeddings.embed_query(query)
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarities = np.dot(self.vector_db['embeddings'], query_embedding.T).flatten()
            
            # ìƒìœ„ ê²°ê³¼ ì¸ë±ìŠ¤
            top_indices = np.argsort(similarities)[::-1][:5]
            
            results = []
            for idx in top_indices:
                chunk = self.vector_db['chunks'][idx]
                # ì²­í¬ì—ì„œ ë§›ì§‘ ì •ë³´ ì¶”ì¶œ ì‹œë„
                restaurant_info = self.extract_restaurant_from_chunk(chunk)
                if restaurant_info:
                    restaurant_info['similarity_score'] = float(similarities[idx])
                    results.append(restaurant_info)
            
            return results
            
        except Exception as e:
            print(f"ì˜ë¯¸ì  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_restaurant_from_chunk(self, chunk: str) -> Dict:
        """ì²­í¬ì—ì„œ ë§›ì§‘ ì •ë³´ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë§›ì§‘ ì •ë³´ ì¶”ì¶œ
        lines = chunk.split('\n')
        restaurant_info = {
            'name': '',
            'category': '',
            'location': '',
            'description': chunk[:200] + '...' if len(chunk) > 200 else chunk,
            'source': 'ë²¡í„°DB',
            'match_score': 0
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ë§›ì§‘ ì´ë¦„ íŒ¨í„´ (í•œê¸€ + ìˆ«ì/ì˜ë¬¸)
            if re.match(r'^[ê°€-í£\w\s]+$', line) and len(line) > 2 and len(line) < 50:
                if not restaurant_info['name']:
                    restaurant_info['name'] = line
            
            # ì¹´í…Œê³ ë¦¬ íŒ¨í„´
            if any(keyword in line for keyword in ['í•œì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ì–‘ì‹', 'í•´ì‚°ë¬¼', 'ê³ ê¸°', 'ì¹˜í‚¨', 'í”¼ì', 'ì¹´í˜']):
                restaurant_info['category'] = line
        
        return restaurant_info if restaurant_info['name'] else None
    
    def hybrid_search(self, query: str) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ì˜ë¯¸ì  ê²€ìƒ‰)"""
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        
        # 1. í‚¤ì›Œë“œ ê²€ìƒ‰
        keyword_results = self.search_by_keywords(query)
        print(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼: {len(keyword_results)}ê°œ")
        
        # 2. ì˜ë¯¸ì  ê²€ìƒ‰
        semantic_results = self.search_by_semantic(query)
        print(f"ì˜ë¯¸ì  ê²€ìƒ‰ ê²°ê³¼: {len(semantic_results)}ê°œ")
        
        # 3. ê²°ê³¼ í†µí•©
        combined_results = self.combine_results(keyword_results, semantic_results)
        
        # 4. ë‹µë³€ ìƒì„±
        answer = self.generate_answer(query, combined_results)
        
        return {
            'query': query,
            'keyword_results': keyword_results,
            'semantic_results': semantic_results,
            'combined_results': combined_results,
            'answer': answer
        }
    
    def combine_results(self, keyword_results: List[Dict], semantic_results: List[Dict]) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ í†µí•©"""
        combined = []
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        for result in keyword_results:
            result['search_type'] = 'keyword'
            combined.append(result)
        
        # ì˜ë¯¸ì  ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        for semantic_result in semantic_results:
            is_duplicate = False
            for existing in combined:
                if (semantic_result.get('name') and 
                    existing.get('name') and 
                    semantic_result['name'] in existing['name'] or 
                    existing['name'] in semantic_result['name']):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                semantic_result['search_type'] = 'semantic'
                combined.append(semantic_result)
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        combined.sort(key=lambda x: x.get('match_score', 0) + x.get('similarity_score', 0), reverse=True)
        
        return combined[:10]  # ìƒìœ„ 10ê°œ
    
    def generate_answer(self, query: str, results: List[Dict]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
        if not results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
        
        answer_parts = []
        
        # ì¿¼ë¦¬ ë¶„ì„
        if any(keyword in query for keyword in ['ì¶”ì²œ', 'ì–´ë””', 'ì¢‹ì€']):
            answer_parts.append(f"'{query}'ì— ëŒ€í•œ ë§›ì§‘ì„ ì°¾ì•„ë“œë ¸ìŠµë‹ˆë‹¤! ğŸ½ï¸")
        else:
            answer_parts.append(f"'{query}' ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤! ğŸ½ï¸")
        
        # ê²°ê³¼ ìš”ì•½
        answer_parts.append(f"\nì´ {len(results)}ê°œì˜ ë§›ì§‘ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
        
        # ëª¨ë“  ë§›ì§‘ ìƒì„¸ ì •ë³´ í‘œì‹œ
        for i, restaurant in enumerate(results, 1):
            name = restaurant.get('name', 'ì´ë¦„ ì—†ìŒ')
            category = restaurant.get('category', '')
            location = restaurant.get('location', '')
            rating = restaurant.get('rating', 0)
            address = restaurant.get('address', '')
            phone = restaurant.get('phone', '')
            hours = restaurant.get('hours', '')
            menu = restaurant.get('menu', '')
            
            info = f"\n{i}. **{name}**"
            if category:
                info += f" ({category})"
            if location:
                info += f" - {location}"
            if rating:
                info += f" â­ {rating}"
            if address:
                info += f"\n   ğŸ“ {address}"
            if phone:
                info += f"\n   ğŸ“ {phone}"
            if hours:
                info += f"\n   ğŸ•’ {hours}"
            if menu:
                # ë©”ë‰´ê°€ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ í‘œì‹œ
                menu_preview = menu[:100] + "..." if len(menu) > 100 else menu
                info += f"\n   ğŸ½ï¸ {menu_preview}"
            
            answer_parts.append(info)
        
        answer_parts.append("\në” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§›ì§‘ ì´ë¦„ì„ ë§ì”€í•´ì£¼ì„¸ìš”!")
        
        return "".join(answer_parts)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
restaurant_search = None

def get_restaurant_search(gemini_api_key):
    """ë§›ì§‘ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global restaurant_search
    if restaurant_search is None:
        restaurant_search = HybridRestaurantSearch(gemini_api_key)
    return restaurant_search

def search_restaurants(query: str, gemini_api_key: str) -> str:
    """ë§›ì§‘ ê²€ìƒ‰ í•¨ìˆ˜ (RAG ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©)"""
    search_system = get_restaurant_search(gemini_api_key)
    
    # ì§€ì—­ëª… ë¶„ì„ ë° êµ¬ ì •ë³´ ì¶”ê°€
    enhanced_query = query
    try:
        import google.generativeai as genai
        from config import GEMINI_API_KEY
        
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-1.5-flash")
        
        # ì§€ì—­ëª… ë¶„ì„ í”„ë¡¬í”„íŠ¸
        location_prompt = f"""
ë‹¤ìŒ ê²€ìƒ‰ì–´ì—ì„œ ë¶€ì‚°ì˜ ì§€ì—­ëª…ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , í•´ë‹¹ ì§€ì—­ì´ ì–´ëŠ êµ¬ì— ì†í•˜ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.
ë¶€ì‚° ì£¼ìš” ì§€ì—­ê³¼ êµ¬ ë§¤í•‘:
- ì„œë©´, ë¶€ì „ë™, ë¶€ì „ â†’ ë¶€ì „êµ¬
- í•´ìš´ëŒ€, í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥ â†’ í•´ìš´ëŒ€êµ¬  
- ë‚¨í¬ë™, ìš©ë‘ì‚°, ê´‘ë³µë™ â†’ ì¤‘êµ¬
- ê´‘ì•ˆë¦¬, ê´‘ì•ˆëŒ€êµ, ìˆ˜ì˜ â†’ ìˆ˜ì˜êµ¬
- ë™ë˜, ì˜¨ì²œë™ â†’ ë™ë˜êµ¬
- ë¶€ì‚°ëŒ€, ì¥ì „ë™ â†’ ê¸ˆì •êµ¬
- ì‚¬ìƒ, ì‚¬ìƒêµ¬ â†’ ì‚¬ìƒêµ¬
- ì—°ì œ, ì—°ì‚°ë™ â†’ ì—°ì œêµ¬
- ë¶êµ¬, êµ¬í¬ â†’ ë¶êµ¬
- ê°•ì„œ, ëª…ì§€ â†’ ê°•ì„œêµ¬
- ê¸°ì¥, ì¥ì•ˆ â†’ ê¸°ì¥êµ°

ê²€ìƒ‰ì–´: "{query}"

ì§€ì—­ëª…ì´ ìˆìœ¼ë©´ "ì§€ì—­ëª…:êµ¬ëª…" í˜•íƒœë¡œ, ì—†ìœ¼ë©´ "ì—†ìŒ"ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
ì˜ˆì‹œ: "ì„œë©´ ë§›ì§‘" â†’ "ì„œë©´:ë¶€ì „êµ¬", "í•´ìš´ëŒ€ í•´ì‚°ë¬¼" â†’ "í•´ìš´ëŒ€:í•´ìš´ëŒ€êµ¬", "í”¼ì ë§›ì§‘" â†’ "ì—†ìŒ"
"""
        
        location_response = model.generate_content(location_prompt, generation_config={"max_output_tokens": 128, "temperature": 0.1})
        location_result = location_response.text.strip()
        
        # ì§€ì—­ëª…ì´ ë°œê²¬ë˜ë©´ êµ¬ ì •ë³´ë¥¼ ê²€ìƒ‰ì–´ì— ì¶”ê°€
        if ":" in location_result and location_result != "ì—†ìŒ":
            location_parts = location_result.split(":")
            if len(location_parts) == 2:
                original_location = location_parts[0].strip()
                district = location_parts[1].strip()
                enhanced_query = f"{query} {district}"
                print(f"ì§€ì—­ëª… ë¶„ì„: '{query}' -> '{original_location}:{district}' -> '{enhanced_query}'")
        
    except Exception as e:
        print(f"ì§€ì—­ëª… ë¶„ì„ ì˜¤ë¥˜: {e}")
        enhanced_query = query
    
    # ì™¸êµ­ì–´ ê²€ìƒ‰ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­
    translated_query = enhanced_query
    try:
        # ê°„ë‹¨í•œ ì™¸êµ­ì–´ ê°ì§€ (í•œê¸€ì´ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°)
        if not any('\u3131' <= char <= '\u3163' or '\uac00' <= char <= '\ud7af' for char in enhanced_query):
            # Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ë²ˆì—­
            import google.generativeai as genai
            from config import GEMINI_API_KEY
            
            genai.configure(api_key=GEMINI_API_KEY)
            model = genai.GenerativeModel("gemini-1.5-flash")
            
            prompt = f"Translate the following text to Korean and return only the translation. This is for restaurant search in Busan, so translate food-related terms appropriately.\nText: {enhanced_query}"
            response = model.generate_content(prompt, generation_config={"max_output_tokens": 256, "temperature": 0.1})
            translated_query = response.text.strip()
            print(f"ì™¸êµ­ì–´ ê²€ìƒ‰ì–´ ë²ˆì—­: '{enhanced_query}' -> '{translated_query}'")
    except Exception as e:
        print(f"ê²€ìƒ‰ì–´ ë²ˆì—­ ì˜¤ë¥˜: {e}")
        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
        translated_query = enhanced_query
    
    result = search_system.hybrid_search(translated_query)
    return result['answer'] 